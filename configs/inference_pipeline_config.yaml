pipeline:
  - name: embedding
    class: src.components.embedder.DocEmbedder
    method: from_vs
    params:
      model_name: "all-MiniLM-L6-v2"
      vs_name: "faiss_index_google_genai_risk_mgmt"
    input:
    output: vectorstore

  - name: retrieving
    class: src.components.retriever.ChunkRetriever
    method: retrieve
    params:
      retriever_search_type: "similarity"
      retriever_search_kwargs: {"k":20}
    input:
      vectorstore: vectorstore
    output: retriever

  - name: reranking
    class: src.components.reranker.Reranker
    method: rerank
    params:
      k_rerank: 5 # choose top k reranker score
      model_rerank: "gemini-2.5-flash"
      model_rerank_provider: "google_genai"
      temperature_rerank: 0
      top_k_rerank: 5 # top k token in generation of the rerank score
      top_p_rerank: 0.8
      prompt_name: "system-reranker-prompt"
      prompt_version: "latest"
    input:
      retriever: retriever
      query:
    output: reranked_document

  - name: autorating
    class: src.components.autorater.Autorater
    method: autorate
    params:
      model_autorate: "gemini-2.5-flash"
      model_autorate_provider: "google_genai"
      temperature_autorate: 0
      top_k_autorate: 5
      top_p_autorate: 0.8
      prompt_name: "system-autorater-prompt"
      prompt_version: "latest"
    input:
      reranked_document: reranked_document
      query:
    output: autorated_document

  - name: generating
    class: src.components.generator.GeneratorLLM
    method: llm
    params:
      model: "gemini-2.5-flash"
      model_provider: "google_genai"
      temperature: 0
      top_k: 5 # top k token in generation of the rerank score
      top_p: 0.9
      prompt_name: "system-system-prompt"
      prompt_version: "latest"
    input:
    output:

