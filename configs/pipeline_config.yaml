pipeline:
  - name: load_data
    class: components.loader.DataLoader
    method: load_from_wikipedia_api
    params:
      metadata: {"source": "battle of stalingrad"}
    input:
      title: "Battle of Stalingrad"
    output: docs

  - names: chunking
    class: components.chunker.TextSplitter
    method: split
    params:
      chunk_size: 200
      chunk_overlap: 10
    input:
      docs: docs
    output: split_docs

  - names: embedding
    class: components.embedder.DocEmbedder
    method: embed
    params:
      model_name: "all-MiniLM-L6-v2"
    input:
      split_docs: split_docs
    output: vectorstore

  - names: retrieving
    class: components.retriever.ChunkRetriever
    method: retrieve
    params:
      retriever_search_type: "similarity"
      retriever_search_kwargs: {"k":20}
    input:
      vectorstore: vectorstore
    output: retriever

  - names: reranking
    class: components.retriever.RerankRetriever
    method:
    params:
      retriever: retriever
      k_rerank: 5 # choose top k reranker score
      model_rerank: "llama3"
      temperature_rerank: 0
      top_k_rerank: 1 # top k token in generation of the rerank score
      top_p_rerank: 0.9
    input:
    output: reranked_retriever

  - names: chaining
    class: components.chainer.ComponentChainer
    method: chain
    params:
      ollama_model: "llama3"
      temperature: 0
      top_k: 10 # response generation
      top_p: 0.9
    input:
      reranked_retriever: reranked_retriever
      SYSTEM_PROMPT: "../src/system_prompt.txt"
    output: qa_chain

  - names: run_chain
    class: components.runner.ChainRunner
    method: run
    params:
    input:
      qa_chain: qa_chain
      USER_QUERY: "../src/data/prompt.txt"
    output: response


