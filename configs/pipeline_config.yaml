pipeline:
  - name: load_data
    class: src.components.loader.DataLoader
    method: load_from_wikipedia_api
    params:
      metadata: {"source": "battle of stalingrad"}
    input:
      title: "Battle of Stalingrad"
    output: docs

  - names: chunking
    class: src.components.chunker.TextSplitter
    method: split
    params:
      chunk_size: 1000
      chunk_overlap: 100
    input:
      docs: docs
    output: split_docs

  - names: embedding
    class: src.components.embedder.DocEmbedder
    method: embed
    params:
      model_name: "all-MiniLM-L6-v2"
    input:
      split_docs: split_docs
    output: vectorstore

  - names: retrieving
    class: src.components.retriever.ChunkRetriever
    method: retrieve
    params:
      retriever_search_type: "similarity"
      retriever_search_kwargs: {"k":50}
    input:
      vectorstore: vectorstore
    output: retriever

  - names: reranking
    class: src.components.retriever.RerankRetriever
    method:
    params:
      retriever: retriever
      k_rerank: 10 # choose top k reranker score
      model_rerank: "gemini-2.5-flash"
      model_rerank_provider: "google_genai"
      temperature_rerank: 0
      top_k_rerank: 5 # top k token in generation of the rerank score
      top_p_rerank: 0.8
    input:
    output: reranked_retriever

  - names: chaining
    class: src.components.chainer.ComponentChainer
    method: chain
    params:
      model: "gemini-2.5-flash"
      model_provider: "google_genai"
      temperature: 0
      top_k: 10 # response generation
      top_p: 0.8
    input:
      reranked_retriever: reranked_retriever
      SYSTEM_PROMPT: "./src/system_prompts/system_prompt.txt"
    output: qa_chain

  - names: run_chain
    class: src.components.runner.ChainRunner
    method: run
    params:
    input:
      qa_chain: qa_chain
      USER_QUERY: "./src/user_query/user_query.txt"
    output: response


